# TranslateX Configuration
# Copy this file to config.yaml and fill in your API keys

# =============================================================================
# PROVIDER SETTINGS
# =============================================================================
# Provider: openai, gemini, groq, openrouter, ollama, ollama-cloud, deepseek
provider: "gemini"

# API Keys (fill in the one you're using)
openai_api_key: ""
openrouter_api_key: ""
groq_api_key: ""
gemini_api_key: "your-gemini-api-key-here"
ollama_api_key: ""      # For Ollama Cloud only
deepseek_api_key: ""    # For DeepSeek (https://platform.deepseek.com)

# Provider notes:
# - ollama: Local, no API key needed, run `ollama serve` first
# - ollama-cloud: Requires ollama_api_key from https://ollama.com/settings/keys
# - deepseek: Requires deepseek_api_key from https://platform.deepseek.com

# =============================================================================
# MODEL SETTINGS
# =============================================================================
# Gemini: gemini-2.0-flash, gemini-2.5-flash, gemini-1.5-flash
# Groq: llama-3.3-70b-versatile, gemma2-9b-it
# OpenAI: gpt-4o-mini, gpt-4o
# OpenRouter: See https://openrouter.ai/models
# Ollama Local: qwen3:8b, qwen3:4b, llama3.1:8b, gemma2:9b, mistral:7b
# Ollama Cloud: qwen3:235b-cloud, qwen3-vl:235b-cloud, qwen3-coder:480b-cloud
# DeepSeek: deepseek-chat (V3), deepseek-reasoner (R1 - reasoning)
model: "gemini-2.0-flash"

# =============================================================================
# TRANSLATION SETTINGS
# =============================================================================
source_lang: "English"
target_lang: "Vietnamese"

# =============================================================================
# PERFORMANCE SETTINGS
# =============================================================================
# Maximum concurrent API requests (auto-adjusted based on model rate limits)
max_concurrent: 5

# Maximum characters per chunk (larger = fewer API calls but may hit token limits)
max_chunk_size: 5000

# =============================================================================
# ADVANCED FEATURES
# =============================================================================

# --- Resume/Checkpoint ---
# Automatically resume from checkpoint if translation was interrupted
auto_resume: true

# --- Batch Processing ---
# Allow processing multiple files when a directory is provided
batch_enabled: true

# --- Translation Cache ---
# Cache translations to avoid re-translating identical text
# Saves API costs when translating similar documents
cache_enabled: true

# --- Context Window ---
# Number of previous translated segments to include as context
# Helps maintain coherent translations across paragraphs
# Set to 0 to disable
context_window: 2

# --- Review Mode ---
# Generate an HTML file showing original and translated text side by side
# Useful for reviewing translation quality
review_mode: false

# --- Error Handling ---
# Maximum retry attempts for failed API calls
max_retries: 3

# --- Logging ---
# Log level: DEBUG, INFO, WARNING, ERROR
log_level: "INFO"

# Save logs to file in output directory
log_to_file: true

# --- Custom Glossary ---
# Path to glossary YAML file with custom term translations
# Set to null or remove to use default technical terms only
glossary_file: "glossary.yaml"
